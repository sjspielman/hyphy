/********************************************************************************************************************/
/********************************************* MODEL DEFINITIONS ****************************************************/
/********************************************************************************************************************/

/**
 * @name models.protein.Baseline.ModelDescription.withGamma
 * @description Define baseline (standard matrix) model w/ +F and *no* four-category gamma rate variation
 */
function prong.Baseline.ModelDescription(type){
    def = Call( models.protein.empirical.plusF_generators[prong.baseline_model], type);
    return def;
}
/**
 * @name models.protein.Baseline.ModelDescription.withGamma
 * @description Define baseline (standard matrix) model w/ +F and *yes* four-category gamma rate variation
 */
function prong.Baseline.ModelDescription.withGamma(type){
    def = prong.Baseline.ModelDescription(type);
	def [utility.getGlobalValue("terms.model.rate_variation")] = rate_variation.types.Gamma.factory ({utility.getGlobalValue("terms.rate_variation.bins") : 4});
    return def;
}


/**
 * @name prong.REV.ModelDescription.freqs
 * @description Define REV model frequencies as empirical
 */
function prong.REV.ModelDescription.freqs (model, namespace, datafilter) {
    model[terms.efv_estimate] = prong.shared_EFV;
    model[terms.model.efv_estimate_name] = terms.frequencies.predefined;
    (model[terms.parameters])[terms.model.empirical] = 0;
    return model;
}

/**
 * @name prong.REV.ModelDescription
 * @description Define a REV model with constant site rates
 */
function prong.REV.ModelDescription (type) {
    def = models.protein.REV.ModelDescription(type);
    if (Type (prong.shared_EFV) == "Matrix") {
        def [terms.model.frequency_estimator] = "prong.REV.ModelDescription.freqs";
    }
    return def;
}

/**
 * @name prong.REV.ModelDescription.withGamma
 * @description Define a REV model with Gamma rate variation
 */
function prong.REV.ModelDescription.withGamma (type) {
    def = prong.REV.ModelDescription(type);
    def [utility.getGlobalValue("terms.model.rate_variation")] = rate_variation.types.Gamma.factory ({utility.getGlobalValue("terms.rate_variation.bins"): 4});
    return def;
}
/********************************************************************************************************************/
/********************************************************************************************************************/
/********************************************************************************************************************/



/********************************************************************************************************************/
/********************************************** FITTING FUNCTIONS ***************************************************/
/********************************************************************************************************************/

/**
 * @name prong.fitBaselineToFile
 * @description Fits an empirical amino acid model to dataset for branch length optimization
 * @param {String} filename - The name of the file containing the dataset to which the amino acid model will be fitted
 * @return the fitted MLE
 */
function prong.fitBaselineToFile (filename) {
    
    
    utility.EnsureKey(prong.analysis_results, prong.index_to_filename[filename]);  
    
    prong.file_info = alignments.ReadNucleotideDataSet ("prong.msa",
                                                              filename);
    prong.name_mapping = prong.file_info[utility.getGlobalValue("terms.data.name_mapping")];
    if (None == prong.name_mapping) { /** create a 1-1 mapping if nothing was done */
        prong.name_mapping = {};
        utility.ForEach (alignments.GetSequenceNames ("prong.msa"), "_value_", "`&prong.name_mapping`[_value_] = _value_");
    }
    utility.ToggleEnvVariable ("GLOBAL_FPRINTF_REDIRECT", "/dev/null");
    ExecuteCommands ('prong.partitions_and_trees = trees.LoadAnnotatedTreeTopology.match_partitions (prong.file_info[terms.data.partitions], prong.name_mapping)',
                     {"0" : "Y"});
    utility.ToggleEnvVariable ("GLOBAL_FPRINTF_REDIRECT", None);



    prong.partition_count      = Abs (prong.partitions_and_trees);
    io.CheckAssertion ("prong.partition_count==1", "This analysis can only handle a single partition");



    prong.filter_specification = alignments.DefineFiltersForPartitions (prong.partitions_and_trees,
                                                                            "prong.msa" ,
                                                                            "prong.filter.",
                                                                            prong.file_info);


    prong.full_trees = utility.Map (prong.partitions_and_trees, "_value_", '_value_[terms.data.tree]');
    prong.full_data_filter = utility.Map (prong.filter_specification, "_value_", "_value_[terms.data.name]");


    /********** Store dataset information *************/
    /* CURRENTLY DOESN'T WORK IN MPI FOR REASONS TBD */
//     prong.output_data_info = { utility.getGlobalValue("terms.json.sequences"): prong.file_info[utility.getGlobalValue("terms.data.sequences")],
//                                      utility.getGlobalValue("terms.json.sites"): prong.file_info[utility.getGlobalValue("terms.data.sites")],
//                                      utility.getGlobalValue("terms.json.trees"): (prong.full_trees["0"])[utility.getGlobalValue("terms.trees.newick_with_lengths")],
//                                      utility.getGlobalValue("terms.json.file"): filename
//                                    };
// 
// 
    // In case there were no branch lengths
//     if (  Abs( (prong.full_trees["0"])[utility.getGlobalValue("terms.branch_length")] ) == 0 ){
//         prong.output_data_info[ utility.getGlobalValue("terms.json.trees") ] = (prong.full_trees["0"])[utility.getGlobalValue("terms.trees.newick")];
//     }
//     utility.ForEach (utility.Keys (prong.name_mapping), "branch_name",
//                              "utility.EnsureKey (prong.output_data_info[terms.original_name], branch_name)");
// 
//     utility.ForEach (utility.Keys (prong.name_mapping), "branch_name",
//                              "(prong.output_data_info[terms.original_name])[branch_name] = prong.name_mapping[branch_name]");
// 
// 
//     (prong.analysis_results[prong.index_to_filename[filename]])[utility.getGlobalValue("terms.json.input")] = prong.output_data_info;
// 
//     
    /****************************************************/

    
    prong.baseline_mle = estimators.FitSingleModel_Ext(prong.full_data_filter,
                                                        prong.full_trees,
                                                        prong.baseline_model_desc,
                                                        None,
                                                        None);
                                                        //
                                                        
    prong.baseline_mle - terms.global; // delete empty key
    return prong.baseline_mle;
}



/**
 * @name prong.handle_baseline_callback
 * @param node - node name which processed the given data
 * @param {Dict} result - Dictionary of fitted information for given data
 * @param {Dict} arguments - Dictionary with single key:value :: 0:datafile name
 * @description Handle MPI callback after fitting a baseline amino acid model (for initial branch length optimization)
 */
function prong.handle_baseline_callback (node, result, arguments) {

    savekey = prong.index_to_filename[arguments[0]];
    
    utility.EnsureKey(prong.analysis_results, savekey);
    utility.EnsureKey(prong.analysis_results[savekey], prong.baseline_phase);
    (prong.analysis_results[savekey])[prong.baseline_phase] = result;
     
    io.ReportProgressMessageMD ("Protein GTR Fitter", "Initial branch length fit",
                                "Received file '" + arguments[0] + "' from node " + node + ". LogL = " + result[terms.fit.log_likelihood]);
}





function prong.fitGTR (current_results) {

    //file_list = utility.Keys (current_results); ---> prong.file_list
    //file_count = utility.Array1D (file_list);   ---> prong.file_list_count
    // NOTE: prong.index_to_filename is {filename:0, filename:1}

    partition_info = {};
    filter_info    = {};
    trees = {};
    initial_values = {terms.global : {}, terms.branch_length : {}};
    index_to_file_name   = {};

    for (file_index = 0; file_index < prong.file_list_count; file_index += 1) {
        file_path = prong.file_list [file_index];
        dataset_name = "prong.msa." + file_index;
        partition_info [file_index] = alignments.ReadNucleotideDataSet (dataset_name, file_path);
        partition_specification = { "0" : {terms.data.name : "all", terms.data.filter_string : "", term.data.tree : ((current_results[file_index])[terms.fit.trees])[0]}};


        filter_info [file_index] = (alignments.DefineFiltersForPartitions (partition_specification,
                                                                            dataset_name ,
                                                                            dataset_name,
                                                                            partition_info [file_index]))[0];
        trees [file_index] = {terms.trees.newick :  ((current_results[file_index])[terms.fit.trees])[0]};
        (initial_values[terms.branch_length])[file_index] = ((current_results[file_index])[terms.branch_length])[0];
    }

    utility.SetEnvVariable ("VERBOSITY_LEVEL", 1);
    utility.ToggleEnvVariable ("AUTO_PARALLELIZE_OPTIMIZE", 1);
    utility.ToggleEnvVariable ("OPTIMIZATION_METHOD", 0);


    for (l1 = 0; l1 < 20; l1 += 1) {
        for (l2 = l1 + 1; l2 < 20; l2 += 1) {
            (initial_values[terms.global]) [terms.aminoacidRate (models.protein.alphabet[l1],models.protein.alphabet[l2])] = {terms.fit.MLE : (prong.initial_rates[models.protein.alphabet[l1]])[models.protein.alphabet[l2]]}; 
        }
    }
    prong.rev_mle = estimators.FitSingleModel_Ext (
                                        utility.Map (filter_info, "_value_", "_value_[terms.data.name]"),
                                        trees,
                                        prong.rev_model,
                                        initial_values,
                                         {terms.run_options.retain_lf_object : TRUE}
                                   );
                                   
    /*   
    // Uncomment these lines if you'd like to save the NEXUS LF.                        
    lf_id = prong.rev.mle[terms.likelihood_function];
    Export(prong.finalphase_LF, ^lf_id);
    fprintf(prong.final_likelihood_function, prong.finalphase_LF);
    */
    prong.rev_mle - terms.likelihood_function;
    
    // Save the rev.mle into the analysis_results, and cache it.
    (^"prong.analysis_results")[prong.final_phase] = prong.rev_mle;

    console.log (""); // clear past the optimization progress line
    utility.SetEnvVariable ("VERBOSITY_LEVEL", 0);
    utility.ToggleEnvVariable ("AUTO_PARALLELIZE_OPTIMIZE", None);
    utility.ToggleEnvVariable ("OPTIMIZATION_METHOD", None);


    // Trees as dictionary for compatibility with rest of the output.
    prong.rev_mle[terms.fit.trees] = utility.SwapKeysAndValues(utility.MatrixToDict(prong.rev_mle[terms.fit.trees]));
    
    return prong.rev_mle;

}
/********************************************************************************************************************/
/********************************************************************************************************************/
/********************************************************************************************************************/



/********************************************************************************************************************/
/********************************************** UTILITY FUNCTIONS ***************************************************/
/********************************************************************************************************************/

function prong.save_options() {
    prong.analysis_results[utility.getGlobalValue("terms.json.options")] = {utility.getGlobalValue("prong.options.frequency_type"): prong.frequency,
                                                                                  utility.getGlobalValue("prong.options.baseline_model"): prong.baseline_model};

    prong.analysis_results[utility.getGlobalValue("terms.json.input")] = {utility.getGlobalValue("terms.json.file"): prong.listfile,
                                                                                "number of datasets": prong.file_list_count};

    /* Temporarily, we save input file information here in a highly redundant fashion, but doesn't seem possible to do in MPI...? */
    for (file_index = 0; file_index < prong.file_list_count; file_index += 1) {
    
        filename = prong.file_list[file_index];
        utility.EnsureKey(prong.analysis_results, file_index);  
    
        prong.file_info = alignments.ReadNucleotideDataSet ("prong.msa",
                                                                      filename);
        prong.name_mapping = prong.file_info[utility.getGlobalValue("terms.data.name_mapping")];
        if (None == prong.name_mapping) { /** create a 1-1 mapping if nothing was done */
            prong.name_mapping = {};
            utility.ForEach (alignments.GetSequenceNames ("prong.msa"), "_value_", "`&prong.name_mapping`[_value_] = _value_");
        }
        utility.ToggleEnvVariable ("GLOBAL_FPRINTF_REDIRECT", "/dev/null");
        ExecuteCommands ('prong.partitions_and_trees = trees.LoadAnnotatedTreeTopology.match_partitions (prong.file_info[terms.data.partitions], prong.name_mapping)',
                          {"0" : "Y"});
        utility.ToggleEnvVariable ("GLOBAL_FPRINTF_REDIRECT", None);


        prong.filter_specification = alignments.DefineFiltersForPartitions (prong.partitions_and_trees,
                                                                                    "prong.msa" ,
                                                                                    "prong.filter.",
                                                                                    prong.file_info);
        prong.tree = utility.Map (prong.partitions_and_trees, "_value_", '_value_[terms.data.tree]');


        prong.output_data_info = { utility.getGlobalValue("terms.json.sequences"): prong.file_info[utility.getGlobalValue("terms.data.sequences")],
                                         utility.getGlobalValue("terms.json.sites"): prong.file_info[utility.getGlobalValue("terms.data.sites")],
                                         utility.getGlobalValue("terms.json.trees"): (prong.tree["0"])[utility.getGlobalValue("terms.trees.newick_with_lengths")],
                                         utility.getGlobalValue("terms.json.file"): filename,
                                         utility.getGlobalValue("terms.original_name"): {}
                                       };
        
        
        //In case there were no branch lengths
        if (  Abs( (prong.tree["0"])[utility.getGlobalValue("terms.branch_length")] ) == 0 ){
            prong.output_data_info[ utility.getGlobalValue("terms.json.trees") ] = (prong.full_trees["0"])[utility.getGlobalValue("terms.trees.newick")];
        }
        utility.ForEach (utility.Keys (prong.name_mapping), "branch_name",
                                 "utility.EnsureKey (prong.output_data_info[terms.original_name], branch_name)");
        
        utility.ForEach (utility.Keys (prong.name_mapping), "branch_name",
                                 "(prong.output_data_info[terms.original_name])[branch_name] = prong.name_mapping[branch_name]");
        
        
        (prong.analysis_results[file_index])[utility.getGlobalValue("terms.json.input")] = prong.output_data_info;   
    }
}


lfunction prong.startTimer(timers, key) {
    timers[key] = {
        utility.getGlobalValue("terms.timers.timer"): Time(1),
    };

}
lfunction prong.stopTimer(timers, key) {
    (timers[key])[utility.getGlobalValue("terms.timers.timer")] = Time(1) - (timers[key])[utility.getGlobalValue("terms.timers.timer")];
}







// From the fitted model results, create EFV array which can be used for custom model 
function prong.extract_efv () {
    if (prong.frequency_type == prong.ml_freq){
        fitted_efv = {20, 1};
        for (i = 0; i < 20; i+=1)
        {
            efv_search = terms.characterFrequency(models.protein.alphabet[i]);  
            fitted_efv[i] = ((prong.gtr_fit[terms.global])[efv_search])[terms.fit.MLE];
    
        }
        norm =  +fitted_efv;
        fitted_efv = fitted_efv * (1/norm);
    }
    if (prong.frequency_type == prong.emp_freq) {
        fitted_efv = (prong.gtr_fit[terms.efv_estimate])["VALUEINDEXORDER"][0];
    }
    //console.log((results[terms.efv_estimate])["VALUEINDEXORDER"][0]);
    //console.log(prong.fitted_efv);
    return fitted_efv
}




// From the fitted model results and create rate dictionary which can be used for .fitted_model
function prong.extract_rates() {

    rij = {};
    for (l1 = 0; l1 < 20 - 1; l1 += 1) {
        rij[models.protein.alphabet[l1]] = {};
        for (l2 = l1 + 1; l2 < 20; l2 += 1) {
    
            rate_search = terms.aminoacidRate(models.protein.alphabet[l1], models.protein.alphabet[l2]);       
            (rij[models.protein.alphabet[l1]])[models.protein.alphabet[l2]] = ((prong.gtr_fit[terms.global])[rate_search])[terms.fit.MLE];
        }
    }
    return rij
}


function prong.write_model_to_file() {

    prong.external_order   = {{"A", "R", "N", "D", "C", "Q", "E", "G", "H", "I", "L", "K", "M", "F", "P", "S", "T", "W", "Y", "V"}};
    prong.hyphy_order_dict = utility.MatrixToDict(models.protein.alphabet); 

    if (prong.output_format == prong.output_hyphy)
    {
        prong.save_hyphy_model();
    }

    if (prong.output_format == prong.output_paml)
    {
        prong.save_paml_model();
    }
    if (prong.output_format == prong.output_raxml)
    {
        prong.save_raxml_model();
    }
    if (prong.output_format == prong.output_all)
    {
        prong.save_raxml_model();
        prong.save_paml_model();
        prong.save_hyphy_model();
    }
}


function prong.save_hyphy_model(){
    fprintf(prong.output_model_prefix + prong.hyphy_model_ext, CLEAR_FILE, "Rij = " + prong.final_rij + ";");
    fprintf(prong.output_model_prefix + prong.hyphy_model_ext, "\n\n\n");
    fprintf(prong.output_model_prefix + prong.hyphy_model_ext, "EFV = " + prong.final_efv + ";");
}

function prong.save_raxml_model(){

    prong.raxml_output = "";
    prong.raxml_file = prong.output_model_prefix + prong.raxml_model_ext;
    
    for (i = 0; i < 20; i +=1)
    {
        for (j = 0; j < 20; j += 1)
        {
        
            if (i == j)
            {
                prong.raxml_output += "0.0\n";
            }
            else
            {
                prong.aa1 = prong.external_order[i];
                prong.aa2 = prong.external_order[j];
        
                if (prong.aa1 < prong.aa2)
                {
                    prong.rate = (prong.final_rij[prong.aa1])[prong.aa2];
                }
                else
                {
                    prong.rate = (prong.final_rij[prong.aa2])[prong.aa1];
                }
                prong.raxml_output += prong.rate;
                prong.raxml_output += "\n"; 
            }
        }    
    }
    for (i = 0; i < 20; i += 1)
    {
        prong.raxml_output += prong.final_efv[ prong.hyphy_order_dict[prong.external_order[i]] ];
        // strip hack
        if (i <= 18){
            prong.raxml_output += "\n";
        }
    }

    fprintf(prong.raxml_file, CLEAR_FILE, prong.raxml_output);
}




function prong.save_paml_model(){

    prong.paml_output = "";
    prong.paml_file = prong.output_model_prefix + prong.paml_model_ext;

    for (i = 1; i < 20; i +=1)
    {
        prong.row = "";
        for (j = 0; j < i; j += 1)
        {
        
            prong.aa1 = prong.external_order[i];
            prong.aa2 = prong.external_order[j];
        
            if (prong.aa1 < prong.aa2){
                prong.rate = (prong.final_rij[prong.aa1])[prong.aa2];
            }
            else{
                prong.rate = (prong.final_rij[prong.aa2])[prong.aa1];
            }
            
            prong.row += prong.rate;
            // strip hack
            if (j != (i-1)){
                prong.row += " ";
            }
        }
    
        prong.paml_output += prong.row + "\n";
    }

    prong.paml_output += "\n";
    for (i = 0; i < 20; i += 1)
    {
        prong.paml_output += prong.final_efv[ prong.hyphy_order_dict[prong.external_order[i]] ];
        // strip hack
        if (i <= 18){
            prong.paml_output += " ";
        }
    }
    fprintf(prong.paml_file, CLEAR_FILE, prong.paml_output);
}
/********************************************************************************************************************/
/********************************************************************************************************************/
/********************************************************************************************************************/




